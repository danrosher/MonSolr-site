'use strict';(function(){const indexCfg={};indexCfg.doc={id:'id',field:['title','content'],store:['title','href'],};const index=FlexSearch.create(indexCfg);window.geekdocSearchIndex=index;index.add({'id':0,'href':'/MonSolr-site/usage/dependencies/','title':"Dependencies",'content':"What required to install and run MonSolr\n   Dependencies requirements     Dependencies requirements  For compilation/runtime at least jdk11 mvn MongoDB releases from versions 2.6 to 4.2 [and \u0026gt;= 3.6 for changestreams] Solr \u0026gt;= 7.x application built with solrj maven 8.6.2  "});index.add({'id':1,'href':'/MonSolr-site/usage/getting_started/','title':"Getting Started",'content':"This page tells you how to get started with MonSolr\n Installation Usage Configuration   Installation  git clone https://github.com/danrosher/MonSolr.git cd MonSolr mvn install ## then scp jar if required # scp target/MonSolr-1.0-SNAPSHOT-jar-with-dependencies.jar \u0026lt;host\u0026gt; Usage # Run with : java -Dlog4j.configuration=file:///log4j.properties -Dconfig=/path/to/config.toml -jar MonSolr-1.0-SNAPSHOT-jar-with-dependencies.jar Configuration List of config options. Optional ones commented out showing defaults.\nConfig requires one of mongo-pipeline, or a [[changestream.*]] . mongo-pipeline to do anything useful\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74  mongo-url=\u0026#34;mongodb://localhost\u0026#34; mongo-db=\u0026#34;mongodb\u0026#34; mongo-collection=\u0026#34;mongocol\u0026#34; solr-collection=\u0026#34;$solr_collection\u0026#34; solr-unique-key=\u0026#34;id\u0026#34; solr-url=\u0026#34;http://localhost/solr\u0026#34; # solr-writer-batch=1000 # mongo-start-epoch=? #resume after this epoch, ignore any resumetokens # mongo-batchsize=1 # mongo-pipeline=\u0026#39;\u0026#39;\u0026#39; # [ # {$match: {\u0026#39;ad\u0026#39;: {$exists:true}}}, # {\u0026#39;$addFields\u0026#39;: { # \u0026#39;solr_collection\u0026#39;: { # $arrayElemAt: [ # [\u0026#39;AD\u0026#39;,\u0026#39;XX\u0026#39;,\u0026#39;FR\u0026#39;,\u0026#39;AE\u0026#39;,\u0026#39;\u0026#39;], # {$indexOfArray: [ # [\u0026#39;ad\u0026#39;,\u0026#39;xx\u0026#39;,\u0026#39;fr\u0026#39;,\u0026#39;ae\u0026#39;], # { $substr: [ \u0026#34;$id\u0026#34;, 0, 2 ]} ]} ]}, # }} # ] # \u0026#39;\u0026#39;\u0026#39; # sync-collection=\u0026#34;monsolr\u0026#34; # solr-num-writers=\u0026#34;1\u0026#34; # solr-writer-batch=\u0026#34;1000\u0026#34; # #solr-writer-delay=\u0026#34;1\u0026#34; #only for changestream.* # app-queue-size=\u0026#34;1\u0026#34; #default to writers*solr-writer-batch # app-tracker-delay-secs=1 # [changestream only] default to 0 (no tracking), number of secs to track # app-progress-delay-secs=1 # default to 0 (to progress reporting), number of secs for reporting # [[changestream.update]] #one of create/replace/update/delete # name=\u0026#34;update\u0026#34; # #create: add document, ONLY if solr doc does not already exist # #replace: add document, replace if solr doc already exist # #update: atomic update docuemnt ONLY if it already exists (using optimistic concurrency) # #delete: remove document # mongo-pipeline=\u0026#39;\u0026#39;\u0026#39; # [ # {\u0026#39;$match\u0026#39;: {\u0026#39;$and\u0026#39; : [ # {\u0026#39;fullDocument.id\u0026#39; : {\u0026#39;$exists\u0026#39;:true}}, # {\u0026#39;operationType\u0026#39;: \u0026#39;update\u0026#39;}, # {\u0026#39;updateDescription.updatedFields.id\u0026#39; : {\u0026#39;$exists\u0026#39;:false}} # ]}}, # {\u0026#39;$project\u0026#39;: { # \u0026#39;fullDocument.id\u0026#39;:1, # \u0026#39;fullDocument.title\u0026#39;:1, # \u0026#39;updateDescription\u0026#39;:1, # \u0026#39;clusterTime\u0026#39;:1, # }}, # {\u0026#39;$addFields\u0026#39;: { # \u0026#39;updateDescription.updatedFields.newField\u0026#39;: \u0026#39;this is an added field!\u0026#39;, # \u0026#39;fullDocument.solr_collection\u0026#39;:\u0026#39;new_jobs\u0026#39; # }} # ] # \u0026#39;\u0026#39;\u0026#39; # {\u0026#39;$project\u0026#39;: { # \u0026#39;fullDocument.id\u0026#39;:1, # \u0026#39;fullDocument.title\u0026#39;:1 # }}, # {\u0026#39;$addFields\u0026#39;: {\u0026#39;fullDocument.newField\u0026#39;: \u0026#39;this is an added field!\u0026#39;}} # ] # [[changestream.create]] # name=\u0026#34;create2\u0026#34; # # [[changestream.replace]] # name=\u0026#34;replace\u0026#34; # # [[changestream.update]] # name=\u0026#34;update\u0026#34; # # [[changestream.delete]] # name=\u0026#34;delete\u0026#34;   See Configuration for details about each\n"});index.add({'id':2,'href':'/MonSolr-site/usage/configuration/','title':"Configuration",'content':"What required to install and run MonSolr\n   mongo-url mongo-db mongo-collection solr-collection  solr-unique-key solr-url solr-writer-batch mongo-start-epoch* mongo-batchsize mongo-pipeline sync-collection* solr-num-writers solr-writer-delay* app-queue-size app-tracker-delay-secs* app-progress-delay-secs   ChangeStream config options  name mongo-pipeline     mongo-url Connection string for mongo e.g. mongodb://master,slave1,slave2\nmongo-db Mongo Database\nmongo-collection Mongo collection\nsolr-collection  Solr Collection. This can be static like solr-collection=\u0026quot;my-solr-collection\u0026quot; OR dynamic like solr-collection=\u0026quot;$solr_collection\u0026quot; where we use the mongo field value to pick the solr collection. This is so that document from a single mongo collection can be routed to the appropriate solr collection\nsolr-unique-key This is the solr unique key, required for deletes for example\nsolr-url Required for connection to Solr\nsolr-writer-batch The number of docs to retain in the app before sending to solr, default to 1000. This makes the export process more efficient.\nmongo-start-epoch* *change stream only Instead of starting from a resumeToken, start from epoch seconds. NOTE: This will restart from the same time on each restart, and will work only if the oplog contains entries since this time.\nmongo-batchsize The cursor batch size to pull this number of docs from mongo on each read from mongo, otherwise the java driver will determine this.\nmongo-pipeline The aggregation pipeline used to select the mongo documents to retrieve. Typically you\u0026rsquo;d use $match, $project and perhaps $addFields.\nFor example the following\n1 2 3 4 5 6  [ {$match: {\u0026#39;id\u0026#39;: {$exists:true}}}, {$project: {\u0026#39;id\u0026#39;: 1,\u0026#39;geo_region\u0026#39;: 1}}, {\u0026#39;$addFields\u0026#39;: { \u0026#39;solr_collection\u0026#39;: \u0026#39;$geo_region\u0026#39; }} ] }}   match docs where the id exists (this is difference from ObjectID for example select fields id and geo_region add field solr_collection = $geo_region, we might use this field to direct the mongo doc to a particular solr_collection with solr_collection = $solr_collection  sync-collection* *change stream only\nIFF app-tracker-delay-secs \u0026gt; 0, then we sync resumeToken and delay to this collection. The mongodb is the same as for mongo-db. resumeToken is used to restart from this position in he oplog/change stream should the application require a restart. delay is the delay between the current time and the clustertime of the last document fetched from the changestream. In essence it\u0026rsquo;s how far in the past the changestream cursor is at, and then how upto date it is.\nsolr-num-writers Number of solr writers writing to solr! Defaults to one\nsolr-writer-delay* *change stream only\nMax number of seconds before forcing a write to solr to ensure solr is timely up to date.\napp-queue-size Max size of internal queue, default to solr-num-writers * solr-writer-batch\napp-tracker-delay-secs* *change stream only\nIFF \u0026gt; 0, max number of secs before tracking updated to sync-collection. We resumeToken and delay, resumeToken is used to restart from this position should the application require a restart. delay is the delay between the current time and the clustertime of the last document fetched from the changestream. In essence it\u0026rsquo;s how far in the past the changestream cursor is at, and then how upto date it is.\napp-progress-delay-secs IFF \u0026gt; 0, max number of secs before we output for each cursor the meanRate,OneMinuteRate, FiveMinuteRate, FifteenMinuteRate, delay(changestream only) and count received from mongo.\nChangeStream config options MonSolr can track changes in changestreams that make the following persistance operations in Solr.\n ```changestream.create`` for creating documents in Solr. The document must not exist for this to have effect. ```changestream.replace`` for creating documents in Solr. The document if exists will be overwritten. ```changestream.update`` for creating documents in Solr. The document will only update if it exists. ```changestream.delete`` for creating documents in Solr. The document, if exists will be removed.  For each of these operations, each of which are optional, we only require 2 fields.\nname This value will be used for storing in the the sync-collection, and output to the logs.\nmongo-pipeline This is the aggregation pipeline used to change the change stream output.. For example\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  [[changestream.update]] name = \u0026#34;update\u0026#34; mongo-pipeline=\u0026#39;\u0026#39;\u0026#39; [ {\u0026#39;$match\u0026#39;: {\u0026#39;$and\u0026#39; : [ {\u0026#39;fullDocument.id\u0026#39; : {\u0026#39;$exists\u0026#39;:true}}, {\u0026#39;operationType\u0026#39;: \u0026#39;update\u0026#39;}, ]}}, {\u0026#39;$project\u0026#39;: { \u0026#39;fullDocument.id\u0026#39;:1, \u0026#39;fullDocument.title\u0026#39;:1, \u0026#39;updateDescription\u0026#39;:1, \u0026#39;clusterTime\u0026#39;:1, }}, {\u0026#39;$addFields\u0026#39;: { \u0026#39;updateDescription.updatedFields.newField\u0026#39;: \u0026#39;this is an added field!\u0026#39;, \u0026#39;fullDocument.solr_collection\u0026#39;:\u0026#39;new_jobs\u0026#39; }} ] \u0026#39;\u0026#39;\u0026#39;   "});index.add({'id':3,'href':'/MonSolr-site/categories/','title':"Categories",'content':""});index.add({'id':4,'href':'/MonSolr-site/','title':"Intro",'content':"MonSolr is a java application to synchronize data from Mongo to Solr. MonSolr can seed the initial import and/or sync data with changestreams.\nFor a full import and Delta (via changestreams) import, mongo field selection is via json in a toml config file by creating aggregation pipeline expressions.\nFeatures  Full and/or Delta import. Mongo field selection/update from config file. Application specific CRUD queries with pipeline expressions.  "});index.add({'id':5,'href':'/MonSolr-site/tags/','title':"Tags",'content':""});index.add({'id':6,'href':'/MonSolr-site/usage/','title':"Usage",'content':""});})();